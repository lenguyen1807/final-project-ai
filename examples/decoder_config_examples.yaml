# Example configurations for different decoders

# GPT-2 Configuration (Default baseline)
gpt2_config:
  model:
    name: "ViT-GPT2"
    encoder:
      type: "vit"
      model_name: "google/vit-base-patch16-224"
      freeze_encoder: false
      projection_dim: null
    decoder:
      type: "gpt2"
      model_name: "gpt2"
      add_cross_attention: true
      freeze_decoder: false
  generation:
    max_length: 100
    top_p: 0.9
    temperature: 1.0
    do_sample: true
    num_beams: 1

# T5 Configuration
t5_config:
  model:
    name: "ViT-T5"
    encoder:
      type: "vit"
      model_name: "google/vit-base-patch16-224"
      freeze_encoder: false
      projection_dim: 512  # T5 hidden size
    decoder:
      type: "t5"
      model_name: "t5-base"
      add_cross_attention: false
      freeze_decoder: false
  generation:
    max_length: 100
    top_p: 0.9
    temperature: 1.0
    do_sample: true
    num_beams: 1

# LLaMA Configuration
llama_config:
  model:
    name: "ViT-LLaMA"
    encoder:
      type: "vit"
      model_name: "google/vit-base-patch16-224"
      freeze_encoder: false
      projection_dim: 4096  # LLaMA hidden size
    decoder:
      type: "llama"
      model_name: "meta-llama/Llama-2-7b-hf"
      add_cross_attention: false
      freeze_decoder: false
  generation:
    max_length: 100
    top_p: 0.9
    temperature: 1.0
    do_sample: true
    num_beams: 1

# Medical Specialized Configuration
medical_specialized_config:
  model:
    name: "ViT-MedicalGPT2"
    encoder:
      type: "vit"
      model_name: "google/vit-base-patch16-224"
      freeze_encoder: false
      projection_dim: null
    decoder:
      type: "gpt2"
      model_name: "gpt2"
      add_cross_attention: true
      freeze_decoder: false
  generation:
    max_length: 150
    top_p: 0.8
    temperature: 0.7
    do_sample: true
    num_beams: 1
  preprocessing:
    text_normalization: true
    lowercase: true
    remove_special_chars: true
    normalize_whitespace: true

# Resource Efficient Configuration
efficient_config:
  model:
    name: "ViT-GPT2-Small"
    encoder:
      type: "vit"
      model_name: "google/vit-small-patch16-224"
      freeze_encoder: false
      projection_dim: null
    decoder:
      type: "gpt2"
      model_name: "gpt2"
      add_cross_attention: true
      freeze_decoder: false
  training:
    batch_size: 8
    learning_rate: 3e-5
    num_epochs: 3
  generation:
    max_length: 80
    top_p: 0.9
    temperature: 1.0
    do_sample: true
    num_beams: 1

# High Quality Configuration
high_quality_config:
  model:
    name: "ViT-LLaMA-Large"
    encoder:
      type: "vit"
      model_name: "google/vit-large-patch16-224"
      freeze_encoder: false
      projection_dim: 4096
    decoder:
      type: "llama"
      model_name: "meta-llama/Llama-2-13b-hf"
      add_cross_attention: false
      freeze_decoder: false
  training:
    batch_size: 4
    learning_rate: 1e-5
    num_epochs: 10
  generation:
    max_length: 200
    top_p: 0.8
    temperature: 0.6
    do_sample: true
    num_beams: 4
